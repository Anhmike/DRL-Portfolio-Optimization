{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Processing (LSTM Training)\n",
    "\n",
    "Now that we have the data processed properly the challenge will be to design, train and test the Long Short-Term Memory (LSTM) network to predict the classifications we have previously extracted.\n",
    "\n",
    "For reference here is the image again of the full Deep Deterministic Policy Gradient (DDPG) Reinforcement Learning (RL) architecture we are trying to build.  Please see the full [2nd report](docs/report2.pdf) for a complete description of this network.\n",
    "\n",
    "![DDPG](docs/ddpg.png \"DDGP\")\n",
    "\n",
    "As you can see there is a LSTM in both the actor and critic networks.  Before the full DDPG can be implemented we must confirm that the LSTM can provide satisfactory signals or the DDPG will just be running on noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load some necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import yaml\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and encode the timeseries data \n",
    "Each data _point_ at time `t` is actually a series of `k` standardized return values from `t-k` to `t` (`x`) and an array of classifications for each `dt` in `prediction_days` (`y`).  Therefore each data point is treated as independent events and will be processed in a random order.  So our first task is to properly structure the timeseries data into indepentent events.\n",
    "\n",
    "Here is an illustration of this transformation for a single asset with two different number of time values.\n",
    "\n",
    "![embedding](docs/embedding.png \"embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the previously saved data and unpack it into Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('settings.yml') as f:\n",
    "    settings = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training-data-raw.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "dt_values = list(data['y'].keys())\n",
    "assets = data['x'][dt_values[0]].columns.tolist()\n",
    "assets.remove(settings['sp500'])\n",
    "dates = data['x'][dt_values[0]].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Process the input data `x` and targets `y`\n",
    "The input `x` to the LSTM network has to have the dimensions [batch_size, time_embedding (k), n_features].  The batch size will be processed later but it is the number of points to feed the network in a single batch.  The number of features in this implementation will be the number of time horizons used to calculate the returns for both the asset to model and also the S&P index.    \n",
    "The output `y` is simply the number of points in the batch and the number of prediction days we will try to predict.    \n",
    "Note for both `x` and `y` there is another dimension not shown for the number of assets to model.  In this implementation the assets will be modeled independently.  Effectively we are ignoring the coupling between assets during the performance prediction.  Once we integrate this into the DRL algorithm, all of these independent signals will be feed into the DRL network.   \n",
    "The S&P signal will be stacked onto the 3rd dimension before training. \n",
    "![shape](docs/data-shape.png \"shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2918, 63, 3, 2)\n",
      "(2918, 63, 3, 1)\n",
      "(2918, 63, 6, 2)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "k = settings['embedding_days']\n",
    "n_t = len(dates) - k + 1\n",
    "\n",
    "# Process x and y\n",
    "x = np.empty((n_t, k, len(dt_values), len(assets)))\n",
    "y = np.empty((n_t, len(dt_values), len(assets)))\n",
    "for i_a, asset in enumerate(assets):\n",
    "    for i_dt, dt in enumerate(dt_values):\n",
    "        y[:, i_dt, i_a] = data['y'][dt].loc[:, asset].values[(k-1):]\n",
    "        for i_n in range(n_t):\n",
    "            x[i_n, :, i_dt, i_a] = data['x'][dt].loc[:, asset].values[i_n:(i_n+k)][::-1]\n",
    "\n",
    "# Process the asset representing the S&P 500 index\n",
    "sp500 = np.empty((n_t, k, len(dt_values), 1))\n",
    "for i_dt, dt in enumerate(dt_values):\n",
    "    for i_n in range(n_t):\n",
    "        sp500[i_n, :, i_dt, 0] = data['x'][dt].loc[:, settings['sp500']].values[i_n:(i_n+k)][::-1]\n",
    "        \n",
    "# Stack the S&P onto x\n",
    "print(x.shape)\n",
    "print(sp500.shape)\n",
    "x = np.concatenate((x, np.concatenate((sp500, sp500), axis=3)), axis=2)\n",
    "print(x.shape)\n",
    "del sp500\n",
    "print(np.max(np.abs((x[:, :, 3:, 0] - x[:, :, 3:, 1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Process the target values `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 assets.\n",
      "2918 total time points.\n",
      "63 time embedding length (k).\n",
      "3 prediction horizons (n_dt).\n"
     ]
    }
   ],
   "source": [
    "print(\"{} assets.\".format(x.shape[3]))\n",
    "print(\"{} total time points.\".format(x.shape[0]))\n",
    "print(\"{} time embedding length (k).\".format(x.shape[1]))\n",
    "print(\"{} prediction horizons (n_dt).\".format(y.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split data into training, validation and testing sets\n",
    "The `test` set is not used during the training and is only used at the very end to evaluate how well the LSTM can predict unseen data.  For our purposes we defined the `test` set as data from the period from the `training_end` date defined in the settings file to the end of our processed data.\n",
    "\n",
    "The `train` set is the data actually used to traing the LSTM where as the `val` set isn't directly used to traing the LSTM but is used to evaluate the training process after each training epoch.  After each epoch we evaluate the model against the `train` and `val` set.  We will continue to train as long as both the `train` and `val` errors decay, but we must stop if the `val` error begins to rise.  A falling `train` error but rising `val` error indicates the model is starting to overfit the training data.  A good description of overfitting is contained in this [wiki page](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "We will follow the stardard practice of splitting our non-test data 9-1 between the `train` and `val` sets.  Note also that we are randomizing the data within the `train` and `val` sets to emilinate any temporal biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_days = np.sum(np.array(dates) >= pd.Timestamp(settings['training_end']))\n",
    "\n",
    "# Test data is simply all the data after the 'training_end' date.\n",
    "x_test = x[-n_test_days:, :, :]\n",
    "y_test = y[-n_test_days:, :, :]\n",
    "\n",
    "# Extract the train and val data and then randomly split 9/1\n",
    "x_train, x_val, y_train, y_val = train_test_split(x[:-n_test_days, :, :, :], \n",
    "                                                  y[:-n_test_days, :, :], \n",
    "                                                  test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now ready, let the real fun begin...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the LSTM network\n",
    "Please see the PyTorch LSTM [documentation](https://pytorch.org/docs/stable/nn.html#lstm) for more detail.    \n",
    "\n",
    "A special thanks for this component goes to the Udacity Deep Learning [Nanodegree](https://www.udacity.com/course/deep-learning-nanodegree--nd101).  Much of this content was derived from the Nanodegree projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check to see if running on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU; ouch, consider making n_epochs very small.\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if train_on_gpu else \"cpu\")\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU!')\n",
    "else: \n",
    "    print('No GPU available, training on CPU; ouch, consider making n_epochs very small.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define the LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn_f\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, n_output, n_layers=1, n_hidden=500, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch LSTM Module plus a linear layer to perform the regression classification.\n",
    "        \n",
    "        Args:\n",
    "            n_features (int): The number of input dimensions\n",
    "            n_output (int): The number prediction horizons\n",
    "            n_layers (int): Number of LSTM layers\n",
    "            n_hidden (int): Number of hidden nodes in the LSTM layers\n",
    "            dropout (float): dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        \n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Set class attributes\n",
    "        self.n_features = n_features\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        # Define the LSTM\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=n_hidden, num_layers=n_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "        \n",
    "        # Linear fully-connected feed forward network\n",
    "        self.fc1 = nn.Linear(n_hidden, int((n_hidden + n_output) / 2.0))\n",
    "        self.fc2 = nn.Linear(int((n_hidden + n_output) / 2.0), n_output)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): [batch_size, k, n_feature] The input to the neural network\n",
    "            hidden (tuple of tensor): The previous hidden state\n",
    "        \n",
    "        Returns:\n",
    "            tensor:  [self.output_size] Ouput of the network\n",
    "            tuple of tensor:  (h_n, c_n) The latest hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Read the batch size\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Get LSTM outpout and updated hidden state\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "    \n",
    "        # Stack up lstm outputs\n",
    "        out = out.contiguous().view(-1, self.n_hidden)\n",
    "\n",
    "        # Feed through fully-connected layer\n",
    "        out = nn_f.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        # Reshape to be batch_size first\n",
    "        out = out.view(batch_size, -1, self.n_output)\n",
    "        out = out[:, -1] # get last batch of labels\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        \n",
    "        Args:\n",
    "            batch_size: The batch_size of the hidden state\n",
    "        \n",
    "        Returns:\n",
    "            tuple of int:  hidden state of dims (n_layers, batch_size, n_hidden)\n",
    "        '''\n",
    "        # Initialize hidden state with zero weights, and move to GPU if available\n",
    "        \n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().float().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().float().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().float(),\n",
    "                      weight.new(self.n_layers, batch_size, self.n_hidden).zero_().float())\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Define the forward and backpropagation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_back_prop(lstm, optimizer, criterion, inp, target, hidden, clip=5.0):\n",
    "    \"\"\"\n",
    "    Forward and backward propagation on the neural network\n",
    "    \n",
    "    Args:\n",
    "        lstm (LSTM): The LSTM object\n",
    "        optimizer: The PyTorch optimizer for the neural network\n",
    "        criterion: The PyTorch loss function\n",
    "        inp (tensor): [batch_size, k, n_feature] The input to the neural network\n",
    "        target (tensor): [batch_size, n_dt * n_output] The neural network output\n",
    "        hidden (tuple of tensor): The previous hidden state\n",
    "        clip (float):  Value to clip gradients to avoid exploding LSTM gradients\n",
    "    \n",
    "    Returns:\n",
    "        float: The loss for the last training batch item\n",
    "        tuple of tensor:  (h_n, c_n) The latest hidden state\n",
    "    \"\"\"\n",
    "    \n",
    "    if(train_on_gpu):\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    " \n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    \n",
    "    # Zero accumulated gradients\n",
    "    lstm.zero_grad()\n",
    "    \n",
    "    # Perform forward propagations, loss calculation and back propagation\n",
    "    output, hidden = lstm(inp, hidden)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Clip the gradients and then perform the weight optimization\n",
    "    nn.utils.clip_grad_norm_(lstm.parameters(), clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(lstm, batch_size, optimizer, criterion, n_epochs, min_v_loss=1.0):\n",
    "   \n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    message = 'Epoch: {:>4} Loss: {:.3f}, V-Loss: {:.3f}, V-Error {:.3f}'\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        lstm.train()\n",
    "        batch_losses = []\n",
    "\n",
    "        # initialize hidden state\n",
    "        hidden = lstm.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(lstm, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "        # printing loss and validation stats\n",
    "        lstm.eval()\n",
    "        val_losses = []\n",
    "        val_errors = []\n",
    "        for batch_i, (inputs, labels) in enumerate(val_loader, 1):\n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(val_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "\n",
    "            output, hidden = lstm(inputs, hidden)\n",
    "            val_losses.append(criterion(output, labels).item())\n",
    "            val_errors.append(torch.abs(labels - output).mean().item())\n",
    "            \n",
    "        v_loss = np.average(val_losses)\n",
    "        if v_loss < min_v_loss:\n",
    "            min_v_loss = v_loss\n",
    "            torch.save(lstm.state_dict(), 'lstm_vloss_{:.3f}.pth'.format(v_loss))\n",
    "        print(message.format(epoch_i, np.average(batch_losses), v_loss, np.average(val_errors)))\n",
    "\n",
    "    return lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train an asset as a test of the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First reduce the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected 1-Day outlook is Very bad.\n",
      "Projected 7-Day outlook is Very bad.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "asset_number = 0\n",
    "batch_size = 200\n",
    "\n",
    "# Slice the assets from x and stack the dt and n_assets for y\n",
    "tmp_x = torch.from_numpy(x_train[:, :, :, asset_number]).float().to(device)\n",
    "tmp_y = torch.from_numpy(y_train[:, :, asset_number]).float().to(device)\n",
    "train_loader = DataLoader(TensorDataset(tmp_x, tmp_y), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Do the same for the verification and test sets\n",
    "tmp_x = torch.from_numpy(x_val[:, :, :, asset_number]).float().to(device)\n",
    "tmp_y = torch.from_numpy(y_val[:, :, asset_number]).float().to(device)\n",
    "val_loader = DataLoader(TensorDataset(tmp_x, tmp_y), shuffle=True, batch_size=batch_size)\n",
    "\n",
    "tmp_x = torch.from_numpy(x_test[:, :, :, asset_number]).float().to(device)\n",
    "tmp_y = torch.from_numpy(y_test[:, :, asset_number]).float().to(device)\n",
    "test_loader = DataLoader(TensorDataset(tmp_x, tmp_y), shuffle=True, batch_size=batch_size)\n",
    "del tmp_x, tmp_y\n",
    "\n",
    "# Print a batch to test\n",
    "data_iter = iter(train_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "decoder = {0.0: 'Very bad', 0.25: 'Bad', 0.5: 'Neutral', 0.75: 'Good', 1.0: 'Very good'}\n",
    "print(\"Projected 1-Day outlook is {}.\".format(decoder[sample_y[0, 0].item()]))\n",
    "print(\"Projected 7-Day outlook is {}.\".format(decoder[sample_y[0, 1].item()]))\n",
    "plt.plot(sample_x[0, :, 0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defined the hyper-parameters and instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defined the hyper-parameters\n",
    "n_layers = 4\n",
    "n_hidden = 500\n",
    "dropout = 0.1\n",
    "\n",
    "# create model and move to gpu if available\n",
    "lstm = LSTM(n_features=x.shape[2], n_output=y.shape[1],\n",
    "            n_layers=n_layers, n_hidden=n_hidden, dropout=dropout)\n",
    "if train_on_gpu:\n",
    "    lstm.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from saved model with validation loss of 0.096\n",
      "Training for 100 epoch(s)...\n",
      "Epoch:    1 Loss: 0.093, V-Loss: 0.101, V-Error 0.266\n",
      "Epoch:    2 Loss: 0.094, V-Loss: 0.098, V-Error 0.259\n",
      "Epoch:    3 Loss: 0.093, V-Loss: 0.102, V-Error 0.267\n",
      "Epoch:    4 Loss: 0.094, V-Loss: 0.097, V-Error 0.260\n",
      "Epoch:    5 Loss: 0.093, V-Loss: 0.098, V-Error 0.261\n",
      "Epoch:    6 Loss: 0.093, V-Loss: 0.101, V-Error 0.265\n",
      "Epoch:    7 Loss: 0.094, V-Loss: 0.100, V-Error 0.263\n",
      "Epoch:    8 Loss: 0.094, V-Loss: 0.100, V-Error 0.263\n",
      "Epoch:    9 Loss: 0.094, V-Loss: 0.097, V-Error 0.258\n",
      "Epoch:   10 Loss: 0.093, V-Loss: 0.099, V-Error 0.260\n",
      "Epoch:   11 Loss: 0.094, V-Loss: 0.097, V-Error 0.261\n",
      "Epoch:   12 Loss: 0.093, V-Loss: 0.097, V-Error 0.259\n",
      "Epoch:   13 Loss: 0.094, V-Loss: 0.099, V-Error 0.263\n",
      "Epoch:   14 Loss: 0.094, V-Loss: 0.098, V-Error 0.259\n",
      "Epoch:   15 Loss: 0.094, V-Loss: 0.099, V-Error 0.264\n",
      "Epoch:   16 Loss: 0.094, V-Loss: 0.098, V-Error 0.262\n",
      "Epoch:   17 Loss: 0.094, V-Loss: 0.101, V-Error 0.265\n",
      "Epoch:   18 Loss: 0.094, V-Loss: 0.096, V-Error 0.259\n",
      "Epoch:   19 Loss: 0.094, V-Loss: 0.099, V-Error 0.263\n",
      "Epoch:   20 Loss: 0.094, V-Loss: 0.100, V-Error 0.264\n",
      "Epoch:   21 Loss: 0.093, V-Loss: 0.100, V-Error 0.264\n",
      "Epoch:   22 Loss: 0.093, V-Loss: 0.102, V-Error 0.264\n",
      "Epoch:   23 Loss: 0.094, V-Loss: 0.102, V-Error 0.267\n",
      "Epoch:   24 Loss: 0.094, V-Loss: 0.098, V-Error 0.263\n",
      "Epoch:   25 Loss: 0.094, V-Loss: 0.100, V-Error 0.264\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Load a previously trained model\n",
    "min_v_loss = 1.0\n",
    "model_name = 'na'\n",
    "for name in glob('lstm_vloss_*.pth'):\n",
    "    try:\n",
    "        v_loss = float(name[11:-4])\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        if v_loss < min_v_loss:\n",
    "            min_v_loss = v_loss\n",
    "            model_name = name\n",
    "if model_name != 'na':\n",
    "    try:\n",
    "        saved_lstm = LSTM(n_features=x.shape[2], n_output=y.shape[1],\n",
    "                          n_layers=n_layers, n_hidden=n_hidden, dropout=dropout)\n",
    "        saved_lstm.load_state_dict(torch.load(model_name))\n",
    "    except:\n",
    "        min_v_loss = 1.0\n",
    "    else:\n",
    "        lstm = saved_lstm\n",
    "        print('Starting from saved model with validation loss of {:.3f}'.format(min_v_loss))\n",
    "    \n",
    "# Restart the training\n",
    "lstm = train_lstm(lstm, batch_size, optimizer, criterion, n_epochs, min_v_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check against test data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "saved_lstm = LSTM(n_features=x.shape[2], n_output=y.shape[1],\n",
    "                  n_layers=n_layers, n_hidden=n_hidden, dropout=dropout)\n",
    "saved_lstm.load_state_dict(torch.load('lstm_vloss_0.096.pth'))\n",
    "lstm = saved_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error total is 0.360.\n",
      "Testing error 1 dt is 0.342.\n",
      "Testing error 5 dt is 0.372.\n",
      "Testing error 21 dt is 0.366.\n",
      "tensor([[0.4065, 0.3342, 0.4869],\n",
      "        [0.4359, 0.3250, 0.7324],\n",
      "        [0.6012, 0.6319, 0.5881],\n",
      "        [0.5149, 0.5358, 0.4996],\n",
      "        [0.5163, 0.5151, 0.4022]], grad_fn=<SliceBackward>)\n",
      "tensor([[0.5000, 1.0000, 0.0000],\n",
      "        [1.0000, 0.5000, 0.7500],\n",
      "        [1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.7500, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = iter(test_loader).next()\n",
    "lstm.eval()\n",
    "output, _ = lstm(test_x, lstm.init_hidden(batch_size))\n",
    "print('Testing error total is {:.3f}.'.format(torch.abs(test_y - output).mean()))\n",
    "for i, dt in enumerate(dt_values):\n",
    "    print('Testing error {} dt is {:.3f}.'.format(dt, torch.abs(test_y[:, i] - output[:, i]).mean()))\n",
    "print(output[:5, :])\n",
    "print(test_y[:5, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
